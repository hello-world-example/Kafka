<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka</title>
    <link>https://hello-world-example.github.io/Kafka/</link>
    <description>Recent content on Kafka</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://hello-world-example.github.io/Kafka/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/_sidebar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/_sidebar/</guid>
      <description> Getting-Started   快速开始  vs RockMQ  Versions  常用命令  Docker 集群   Conf   - Producer  - Consumer   Monitor   JMX 指标  UI 管理工具    Connect..  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Conf/Commons/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Conf/Commons/</guid>
      <description>   属性 默认值 描述     request.timeout.ms                </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Conf/Consumer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Conf/Consumer/</guid>
      <description>Consumer 端 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Conf/Producer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Conf/Producer/</guid>
      <description>Producer 端 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Connect/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Connect/README/</guid>
      <description>Kafka Connect 简介  Kafka Connect 是建立在 Kafka Brocker 之上的数据导入导出工具 Kafka Connect 与 Kafka 一起，但是需要单独启动，先启动 Kafka，再启动 Kafka Connect，两个是独立的进程 Kafka Connect 通过 Source Connect 获取数据，写入到 Topic，通过 Sink Connect 从 Topic 中获取数据，传输到其他地方 官方提供的 Connect 不多，但是其本身也是个开发框架（ org.apache.kafka:connect-api ），屏蔽了 Kafka 连接、推送、偏移 等细节，可以专注于数据处理；Topic 的发送和订阅，由 Connect Framework 处理 分布式部署模式下，提供 RestAPI 接口，用户在线管理 Connect 插件，可以 创建、修改、暂停、恢复、重启 等  部署方式 Standalone mode  适用于 本地环境 的开发和测试 有些情况下着只能使用 Standalone 模式，如：发送本地文件到 Kafka 启动 Connector 时，只能使用配置文件启动，无法使用 Rest 接口  Distributed mode  Kafka Connect 可以与 Kafka Broker 分开部署，Kafka Connect 在多台实例上启动，连接到同一个 Kafka Broker，实现高可用 当然，集群默认启动一个 Connect 节点也是可以的，Connect 节点在集群中的角色可称之为 Worker 当多个 Kafka Connect Worker 中一个 Down 之后，则 Kafka Connect 会把 Down 掉 Worker 的任务分发给集群中的其他节点 因为 Kafka Connect 在 Kafka 集群内存储了连接器配置、状态、偏移信息 等，所以转义过程中是安全的，不会丢失数据 集群模式下启动更简单，启动后，可以通过 RestAPI 管理，配合 Kafka Connect UI 会更加方便  Distributed 模式部署 config/connect-distributed.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Getting-Started/Cli-Quick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Getting-Started/Cli-Quick/</guid>
      <description>常用命令 基础 通用 # --help 查看帮助 ./kafka-topics.sh --help bootstrap-server OR zookeeper  --bootstrap-server 是趋势， --zookeeper 直接操作 ZK，跳过权限，不太建议      &amp;ndash;bootstrap-server &amp;ndash;zookeeper     kafka-topics.sh ✔️ ✔️   kafka-configs.sh  ✔️   kafka-consumer-groups.sh ✔️    kafka-console-consumer.sh ✔️     启动 &amp;amp; 关闭 # 先启动 Zookeeper $ nohup bin/zookeeper-server-start.sh config/zookeeper.properties &amp;amp; # 启动 Kafka $ nohup bin/kafka-server-start.sh config/server.properties &amp;amp; # 关闭 Kafka $ bin/kafka-server-stop.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Getting-Started/Docker-Cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Getting-Started/Docker-Cluster/</guid>
      <description>伪集群安装  https://github.com/wurstmeister/kafka-docker
 Docker Zookeeper $ docker pull zookeeper	$ docker run -d -p 2181:2181 --restart=always --name zookeeper zookeeper:latest Kafka $ docker pull wurstmeister/kafka # 192.168.1.5 是 宿主机 IP # Kafka02 $ docker run -d -p 9092:9092 -p 9292:9292 --restart=always \  --add-host kafka01.kail.xyz:192.168.1.5 \  --add-host kafka02.kail.xyz:192.168.1.5 \  --add-host kafka03.kail.xyz:192.168.1.5 \  -h kafka02.kail.xyz \  -e &amp;#34;KAFKA_ZOOKEEPER_CONNECT=192.168.1.5:2181/kafka&amp;#34; \  -e &amp;#34;KAFKA_LISTENERS=PLAINTEXT://:9092&amp;#34; \  -e &amp;#34;KAFKA_BROKER_ID=2&amp;#34; \  -e &amp;#34;KAFKA_JMX_OPTS=-Dcom.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Getting-Started/VS.Rocket/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Getting-Started/VS.Rocket/</guid>
      <description>Kafka vs RockMQ NameSvr vs. Zookeeper   Kafka 通过 Zookeeper 来进行协调
  RocketMQ 通过自身的 namesrv 进行协调。
  kafka 在具备选举功能，在 Kafka 里面，Master/Slave 的选举，有2步：
 第1步，先通过 ZK 在所有机器中，选举出一个 KafkaController； 第2步，再由这个 Controller，决定每个 partition 的 Master 是谁，Slave 是谁。 Kafka 某个 partition 的 master 挂了，该 partition 对应的某个slave会升级为主对外提供服务。    RocketMQ不具备选举，Master/Slave的角色也是固定的。
 当一个Master挂了之后，你可以写到其他Master上，但不能让一个Slave切换成Master。 那么RocketMq是如何实现高可用的呢？  rocketMq的所有broker节点的角色都是一样，上面分配的topic和对应的queue的数量也是一样的，MQ 只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他broker上面，而并不是这个broker对应的slave升级为主。   RocketMQ 在协调节点的设计上显得更加轻量，用了另外一种方式解决高可用的问题，思路也是可以借鉴的。    吞吐量   Kafka 在消息存储过程中会根据 topic 和 partition 的数量创建物理文件，也就是说创建一个 topic 并指定了 3个 partition，那么就会有3个物理文件目录，也就说说 partition 的数量和对应的物理文件是一一对应的</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Getting-Started/~Quick-Start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Getting-Started/~Quick-Start/</guid>
      <description>快速开始 安装 cd /opt/websuite # 下载 https://kafka.apache.org/downloads $ wget https://archive.apache.org/dist/kafka/1.0.1/kafka_2.12-1.0.1.tgz # 解压 $ tar zxvf kafka_2.12-1.0.1.tgz $ cd kafka_2.12-1.0.1 启动 Kafka # 先启动 Zookeeper $ bin/zookeeper-server-start.sh config/zookeeper.properties # 启动 Kafka $ bin/kafka-server-start.sh config/server.properties 创建 Topic # 创建一个 test 主题，包含 1个分区 和 1个副本 $ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test #&amp;gt; Created topic &amp;#34;test&amp;#34;. # 查看 topic 列表 $ bin/kafka-topics.sh --list --zookeeper localhost:2181 #&amp;gt; test 发送消息 # 发送消息 $ bin/kafka-console-producer.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Getting-Started/~Versions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Getting-Started/~Versions/</guid>
      <description>版本信息 关注的版本  消息格式 v0  0.7：上古版本 0.8：副本机制 0.9：2015.11，增加权限和认证，不建议使用 Consumer API   消息格式 v1  0.10：引入 Kafka Stream   消息格式 v2  0.11：幂等性 Producer API 以及事务（Transaction） API  0.11.0.2：spring-kafka v1 最新版依赖的最新版本 0.11.0.3：0.11.* 最后的版本   1.0：  1.0.1：当前 Broker 的版本 1.0.2：1.0.* 最后的版本   2.0：Stream 的改进    Kafka 兼容性   从 0.10.2.0 开始，在大多数情况下，较新的 Client 可以与较旧的 Broker 通信 Broker &amp;gt;= 0.10.x.x 建议使用 0.11.x.x 或更高的 Client 版本，其使用更简单的线程模型，见 KIP-62 详见 Kafka 兼容性矩阵   Spring Kafka 兼容性  ❤ Spring Kafka 兼容矩阵</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Monitor/jmx-metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Monitor/jmx-metrics/</guid>
      <description>JMX 指标   检查 Broker 端口| 进程 查看 server.log 日志     BytesIn/BytesOut：即 Broker 端每秒入站和出站字节数。你要确保这组值不要接近你的网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。
  NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减负。
  RequestHandlerAvgIdlePercent：即 I/O 线程池线程平均的空闲比例。同样地，如果该值长期小于 30%，你需要调整 I/O 线程池的数量，或者减少 Broker 端的负载。
  UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失。因此，这是一个非常重要的 JMX 指标。
  ISRShrink/ISRExpand：即 ISR 收缩和扩容的频次指标。如果你的环境中出现 ISR 中副本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出 ISR 的原因，并采取适当的措施。
  ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下，Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/Monitor/Ui-Admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/Monitor/Ui-Admin/</guid>
      <description>UI 管理工具 Kafka Tool  官方： http://www.kafkatool.com/download.html
当前版本 2.0.8，For Kafka version 0.11 and later
 Kafka Tool 是一个 C/S 工具，下载指定的安装包安装即可。
使用方式详见：http://www.kafkatool.com/features.html
❤ yahoo/CMAK（Kafka Manager）  Github： https://github.com/yahoo/CMAK
 Docker 方式安装 # 拉取 (支持到 2.0.0.2) $ docker pull solsson/kafka-manager # 运行 $ docker run -d -p 9000:9000 -e &amp;#34;ZK_HOSTS=192.168.1.7:2181&amp;#34; --restart=always --name kafka-manager solsson/kafka-manager xaecbd/KafkaCenter  Github： https://github.com/xaecbd/KafkaCenter
依赖： MySQL、Elasticsearch (7.0+)
 # 安装依赖： MySQL $ docker run -d -p3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/docs/TD/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/docs/TD/</guid>
      <description>TODO Monitoring Kafka Consumer Offsets : https://blog.godatadriven.com/monitoring-kafka-consumer-lag
精确一次语义  https://juejin.im/post/5ce179e1f265da1bd04eb01a  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/Kafka/TD/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/Kafka/TD/</guid>
      <description>查看集群节点（通过 Zookeeper 查看） /opt/websuite/zookeeper/bin/zkCli.sh ls /brokers/ids get /brokers/ids/0
  如何查看 哪个 brocker 是 master get /controller
  topic 列表 bin/kafka-topics.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;list
  两个关键的 Topic 信息 bin/kafka-topics.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;topic info-log &amp;ndash;describe bin/kafka-topics.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;topic exception-log &amp;ndash;describe
  bin/kafka-configs.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;entity-type brokers &amp;ndash;entity-name 0 &amp;ndash;describe
{&amp;ldquo;version&amp;rdquo;:1,&amp;ldquo;partitions&amp;rdquo;:[{&amp;ldquo;topic&amp;rdquo;:&amp;ldquo;exception-log&amp;rdquo;,&amp;ldquo;partition&amp;rdquo;:0,&amp;ldquo;replicas&amp;rdquo;:[1,0]}]} bin/kafka-reassign-partitions.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;reassignment-json-file /opt/websuite/kafka/replication.json &amp;ndash;execute
apache kafka系列之在zookeeper中存储结构： https://blog.csdn.net/lizhitao/article/details/23744675 https://uohzoaix.github.io/studies//2016/01/13/kafka%E9%9B%86%E7%BE%A4%E4%B9%8B%E7%A1%AE%E5%AE%9Aleader/ Kafka 如何手动触发重新选举 https://johng.cn/update-kafka-topic-replicas/
./bin/kafka-configs.sh &amp;ndash;zookeeper s01.soa-solr.ttp.wx:2181 &amp;ndash;alter &amp;ndash;entity-type topics &amp;ndash;entity-name topic-giraffe &amp;ndash;add-config retention.</description>
    </item>
    
  </channel>
</rss>